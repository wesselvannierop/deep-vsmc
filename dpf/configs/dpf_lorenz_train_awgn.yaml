# General
n_particles: 28
likelihood_sigma: 0.1

data:
  salt_prob: 0.0
  awgn_std: [0.1, 0.6]
  image_shape: [28, 28]
sample_dt: 0.02

val_data:
  salt_prob: 0.0
  awgn_std: 0.6
  image_shape: [28, 28]

prior: null
clip_range: [-50.0, 50.0] # clip the particles to this range (x and y could be [-35, 35])
initial_state: [0.0, 35.0] # mu, sigma
transition:
  learn: True
  sigma: 7.0 # only used if learn is False

model: learned # bootstrap, learned
experiment: lorenz

sequence_length: 8
batch_size: 48
# batch_size: 64 # snellius
nr_of_sequences: 1024
# one epoch = 32 steps

val_sequence_length: 128
val_batch_size: 32
val_nr_of_sequences: 32 # == val_batch_size
# wandb:
#   project: dpf
#   entity: wessel

save_path: "{output_dir}/dpf/{experiment}/{timestamp}-{model}-new-awgn={data.awgn_std}"

# For training
training:
  train: True  # if True, train the model, otherwise load the trained model
  n_retrain: 1
  checkpoint: preset:dpf_lorenz_general
  epochs: 120 # this is 32 * 90 = 2880 iterations
  all_observations_at_epoch: 30
  optimizer:
    learning_rate: 1.e-4
    global_clipnorm: 1000.0
  mixture: 2
  equally_weighted_mixture: False
  validation_freq: 3
  enhance_gradient_steps: 2 # maybe try 2 again

validation:
  visualize_idx: null
  enable_compute_elbo: True
  dump_results: False
n_val_epochs: 20